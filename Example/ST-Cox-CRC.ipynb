{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "setup-and-imports",
   "metadata": {},
   "source": [
    "# **TiRank Analysis Pipeline Example**\n",
    "\n",
    "This notebook demonstrates how to use the **TiRank** library to integrate spatial transcriptomics (ST) data and bulk transcriptomics data to identify phenotype-associated spots and determine significant clusters. The analysis includes data loading, preprocessing, model training, prediction, identification of significant clusters, and visualization of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-of-contents",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Setup and Imports](#setup-and-imports)\n",
    "2. [Load Data](#load-data)\n",
    "    - 2.1 [Select Save Paths](#select-save-paths)\n",
    "    - 2.2 [Load Clinical Data](#load-clinical-data)\n",
    "    - 2.3 [Load Bulk Expression Profile](#load-bulk-expression-profile)\n",
    "    - 2.4 [Check Data Consistency](#check-data-consistency)\n",
    "    - 2.5 [Load Spatial Transcriptomics Data](#load-spatial-transcriptomics-data)\n",
    "3. [Preprocessing](#preprocessing)\n",
    "    - 3.1 [Load Saved AnnData Object](#load-saved-anndata-object)\n",
    "    - 3.2 [Preprocess ST Data](#preprocess-st-data)\n",
    "    - 3.3 [Clinical Data Preparation and Splitting](#clinical-data-preparation-and-splitting)\n",
    "    - 3.4 [Gene Pair Transformation](#gene-pair-transformation)\n",
    "4. [Analysis](#analysis)\n",
    "    - 4.1 [TiRank Analysis](#tirank-analysis)\n",
    "        - 4.1.1 [Data Loading and Preparation](#data-loading-and-preparation)\n",
    "        - 4.1.2 [Model Training](#model-training)\n",
    "        - 4.1.3 [Model Inference](#model-inference)\n",
    "        - 4.1.4 [Identify Hubs and Significant Clusters](#identify-hubs-and-significant-clusters)\n",
    "        - 4.1.5 [Visualization](#visualization)\n",
    "    - 4.2 [Differential Expression and Pathway Enrichment Analysis](#differential-expression-and-pathway-enrichment-analysis)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-and-imports",
   "metadata": {},
   "source": [
    "<a id='setup-and-imports'></a>\n",
    "## **1. Setup and Imports**\n",
    "\n",
    "First, we need to import all the necessary libraries and modules required for the analysis. We also set a random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import standard libraries\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Import TiRank modules\n",
    "from TiRank.Model import setup_seed, initial_model_para\n",
    "from TiRank.LoadData import (\n",
    "    load_bulk_clinical,\n",
    "    load_bulk_exp,\n",
    "    check_bulk,\n",
    "    load_st_data,\n",
    "    transfer_exp_profile,\n",
    "    view_dataframe\n",
    ")\n",
    "from TiRank.SCSTpreprocess import (\n",
    "    FilteringAnndata,\n",
    "    Normalization,\n",
    "    Logtransformation,\n",
    "    Clustering,\n",
    "    compute_similarity\n",
    ")\n",
    "from TiRank.Imageprocessing import GetPathoClass\n",
    "from TiRank.GPextractor import GenePairExtractor\n",
    "from TiRank.Dataloader import generate_val, PackData\n",
    "from TiRank.TrainPre import (\n",
    "    tune_hyperparameters,\n",
    "    Predict,\n",
    "    Pcluster,\n",
    "    IdenHub\n",
    ")\n",
    "from TiRank.Visualization import (\n",
    "    plot_score_distribution,\n",
    "    DEG_analysis,\n",
    "    DEG_volcano,\n",
    "    Pathway_Enrichment,\n",
    "    plot_score_umap,\n",
    "    plot_label_distribution_among_conditions,\n",
    "    plot_STmap\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "setup_seed(619)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='load-data'></a>\n",
    "## **2. Load Data**\n",
    "\n",
    "In this section, we load the clinical data, bulk expression profiles, and spatial transcriptomics data required for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-save-paths",
   "metadata": {},
   "source": [
    "<a id='select-save-paths'></a>\n",
    "### **2.1 Select Save Paths**\n",
    "\n",
    "Define the paths where the results and intermediate data will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-save-paths-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory for saving results\n",
    "savePath = \"./ST_Survival_CRC\"\n",
    "\n",
    "# Directory for loading data\n",
    "savePath_1 = os.path.join(savePath, \"1_loaddata\")\n",
    "if not os.path.exists(savePath_1):\n",
    "    os.makedirs(savePath_1, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-clinical-data",
   "metadata": {},
   "source": [
    "<a id='load-clinical-data'></a>\n",
    "### **2.2 Load Clinical Data**\n",
    "\n",
    "Load the clinical data from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-clinical-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your data\n",
    "dataPath = \"./CRC_ST_Prog/\"\n",
    "\n",
    "# Path to clinical data CSV\n",
    "path_to_bulk_cli = os.path.join(dataPath, \"GSE39582_clinical_os.csv\")\n",
    "\n",
    "# Load clinical data\n",
    "bulkClinical = load_bulk_clinical(path_to_bulk_cli)\n",
    "\n",
    "# Optional: View the clinical data DataFrame\n",
    "view_dataframe(bulkClinical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-bulk-expression-profile",
   "metadata": {},
   "source": [
    "<a id='load-bulk-expression-profile'></a>\n",
    "### **2.3 Load Bulk Expression Profile**\n",
    "\n",
    "Load the bulk expression data from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-bulk-expression-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to bulk expression data CSV\n",
    "path_to_bulk_exp = os.path.join(dataPath, \"GSE39582_exp_os.csv\")\n",
    "\n",
    "# Load bulk expression data\n",
    "bulkExp = load_bulk_exp(path_to_bulk_exp)\n",
    "\n",
    "# Optional: View the bulk expression DataFrame\n",
    "view_dataframe(bulkExp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-data-consistency",
   "metadata": {},
   "source": [
    "<a id='check-data-consistency'></a>\n",
    "### **2.4 Check Data Consistency**\n",
    "\n",
    "Ensure that the sample names and identifiers are consistent between the bulk expression data and clinical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-data-consistency-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency between bulk expression and clinical data\n",
    "check_bulk(savePath, bulkExp, bulkClinical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-spatial-transcriptomics-data",
   "metadata": {},
   "source": [
    "<a id='load-spatial-transcriptomics-data'></a>\n",
    "### **2.5 Load Spatial Transcriptomics Data**\n",
    "\n",
    "Load the spatial transcriptomics (ST) data from the specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-st-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing ST data\n",
    "path_to_st_folder = os.path.join(dataPath, \"SN048_A121573_Rep1\")\n",
    "\n",
    "# Load ST data\n",
    "scAnndata = load_st_data(path_to_st_folder, savePath)\n",
    "\n",
    "# Transfer expression profile from AnnData object\n",
    "st_exp_df = transfer_exp_profile(scAnndata)\n",
    "\n",
    "# Optional: View the ST expression DataFrame\n",
    "view_dataframe(st_exp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='preprocessing'></a>\n",
    "## **3. Preprocessing**\n",
    "\n",
    "This section involves filtering, normalizing, and transforming the ST data. We also perform clustering and obtain pathological classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-saved-anndata-object",
   "metadata": {},
   "source": [
    "<a id='load-saved-anndata-object'></a>\n",
    "### **3.1 Load Saved AnnData Object**\n",
    "\n",
    "Load the saved AnnData object from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-anndata-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for preprocessing results\n",
    "savePath_2 = os.path.join(savePath, \"2_preprocessing\")\n",
    "if not os.path.exists(savePath_2):\n",
    "    os.makedirs(savePath_2, exist_ok=True)\n",
    "\n",
    "# Load the saved AnnData object\n",
    "with open(os.path.join(savePath_1, \"anndata.pkl\"), \"rb\") as f:\n",
    "    scAnndata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-st-data",
   "metadata": {},
   "source": [
    "<a id='preprocess-st-data'></a>\n",
    "### **3.2 Preprocess ST Data**\n",
    "\n",
    "Filter the data based on counts and mitochondrial gene proportion, normalize, log-transform, and perform clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess-st-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inference mode (e.g., \"ST\" for spatial transcriptomics)\n",
    "infer_mode = \"ST\"  # Optional parameter\n",
    "\n",
    "# Filtering the data\n",
    "scAnndata = FilteringAnndata(\n",
    "    scAnndata,\n",
    "    max_count=35000,    # Maximum total counts per cell\n",
    "    min_count=5000,     # Minimum total counts per cell\n",
    "    MT_propor=10,       # Maximum percentage of mitochondrial genes\n",
    "    min_cell=10,        # Minimum number of cells expressing the gene\n",
    "    imgPath=savePath_2  # Path to save images/results\n",
    ")\n",
    "# Optional parameters: max_count, min_count, MT_propor, min_cell\n",
    "\n",
    "# Normalize the data\n",
    "scAnndata = Normalization(scAnndata)\n",
    "\n",
    "# Log-transform the data\n",
    "scAnndata = Logtransformation(scAnndata)\n",
    "\n",
    "# Perform clustering on the data\n",
    "scAnndata = Clustering(scAnndata, infer_mode=infer_mode, savePath=savePath)\n",
    "\n",
    "# Compute similarity matrix (optional distance calculation)\n",
    "compute_similarity(\n",
    "    savePath=savePath,\n",
    "    ann_data=scAnndata,\n",
    "    calculate_distance=False  # Set to True if distance calculation is needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "note-pretrain-path",
   "metadata": {},
   "source": [
    "**Note:** Ensure that the `pretrain_path` points to the pre-trained image processing model file included in your package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretrain-path-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the pre-trained image processing model\n",
    "pretrain_path = \"./ctranspath.pth\"\n",
    "\n",
    "# Number of pathological clusters to identify\n",
    "n_patho_cluster = 7  # Optional variable (adjust based on your data)\n",
    "\n",
    "# Perform image processing to get pathological classifications\n",
    "scAnndata = GetPathoClass(\n",
    "    adata=scAnndata,\n",
    "    pretrain_path=pretrain_path,\n",
    "    n_clusters=n_patho_cluster,\n",
    "    image_save_path=os.path.join(savePath_2, \"patho_label.png\")\n",
    "    # Advanced parameters: n_components (PCA components), n_clusters\n",
    ")\n",
    "\n",
    "# Save the processed AnnData object\n",
    "with open(os.path.join(savePath_2, \"scAnndata.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scAnndata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-data-preparation-and-splitting",
   "metadata": {},
   "source": [
    "<a id='clinical-data-preparation-and-splitting'></a>\n",
    "### **3.3 Clinical Data Preparation and Splitting**\n",
    "\n",
    "Prepare the clinical data and split the bulk data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-data-splitting-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the analysis mode (e.g., \"Cox\" for survival analysis)\n",
    "mode = \"Cox\"\n",
    "\n",
    "# Split data into training and validation sets\n",
    "generate_val(\n",
    "    savePath=savePath,\n",
    "    validation_proportion=0.15,  # Optional parameter: proportion of data for validation\n",
    "    mode=mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-pair-transformation",
   "metadata": {},
   "source": [
    "<a id='gene-pair-transformation'></a>\n",
    "### **3.4 Gene Pair Transformation**\n",
    "\n",
    "Extract informative gene pairs for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gene-pair-extractor-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GenePairExtractor with parameters\n",
    "GPextractor = GenePairExtractor(\n",
    "    savePath=savePath,\n",
    "    analysis_mode=mode,\n",
    "    top_var_genes=2000,       # Optional: number of top variable genes to select\n",
    "    top_gene_pairs=1000,      # Optional: number of top gene pairs to select\n",
    "    p_value_threshold=0.05,   # Optional: p-value threshold for gene pair selection\n",
    "    max_cutoff=0.8,           # Optional: upper cutoff for correlation coefficient\n",
    "    min_cutoff=-0.8           # Optional: lower cutoff for correlation coefficient\n",
    ")\n",
    "\n",
    "# Load data for gene pair extraction\n",
    "GPextractor.load_data()\n",
    "\n",
    "# Run the gene pair extraction process\n",
    "GPextractor.run_extraction()\n",
    "\n",
    "# Save the extracted gene pairs\n",
    "GPextractor.save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='analysis'></a>\n",
    "## **4. Analysis**\n",
    "\n",
    "In this section, we perform the TiRank analysis, including model training, prediction, identification of significant clusters, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tirank-analysis",
   "metadata": {},
   "source": [
    "<a id='tirank-analysis'></a>\n",
    "### **4.1 TiRank Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-and-preparation",
   "metadata": {},
   "source": [
    "<a id='data-loading-and-preparation'></a>\n",
    "#### **4.1.1 Data Loading and Preparation**\n",
    "\n",
    "Load and prepare the data for model training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for saving analysis results\n",
    "savePath_3 = os.path.join(savePath, \"3_Analysis\")\n",
    "if not os.path.exists(savePath_3):\n",
    "    os.makedirs(savePath_3, exist_ok=True)\n",
    "\n",
    "# Ensure the 'mode' variable is consistent throughout the analysis\n",
    "mode = \"Cox\"          # Analysis mode (e.g., \"Cox\" for survival analysis)\n",
    "infer_mode = \"ST\"     # Inference mode (e.g., \"ST\" for spatial transcriptomics)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "\n",
    "# Pack the data into DataLoader objects for training and validation\n",
    "PackData(\n",
    "    savePath=savePath,\n",
    "    mode=mode,\n",
    "    infer_mode=infer_mode,\n",
    "    batch_size=1024   # Optional parameter: batch size for DataLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-training",
   "metadata": {},
   "source": [
    "<a id='model-training'></a>\n",
    "#### **4.1.2 Model Training**\n",
    "\n",
    "Initialize model parameters and tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the encoder type for the model (e.g., \"MLP\" for multi-layer perceptron)\n",
    "encoder_type = \"MLP\"  # Optional parameter (options: \"MLP\", \"Transformer\", etc.)\n",
    "\n",
    "# Initialize model parameters\n",
    "initial_model_para(\n",
    "    savePath=savePath,\n",
    "    nhead=2,           # Optional: number of heads in multi-head attention (if using Transformer)\n",
    "    nhid1=96,          # Optional: hidden layer size 1\n",
    "    nhid2=8,           # Optional: hidden layer size 2\n",
    "    n_output=32,       # Optional: output size\n",
    "    nlayers=3,         # Optional: number of layers\n",
    "    n_pred=1,          # Optional: number of predictions (e.g., 1 for regression)\n",
    "    dropout=0.5,       # Optional: dropout rate\n",
    "    mode=mode,\n",
    "    encoder_type=encoder_type,\n",
    "    infer_mode=infer_mode\n",
    ")\n",
    "\n",
    "# Tune hyperparameters using Optuna or other optimization libraries\n",
    "tune_hyperparameters(\n",
    "    savePath=savePath,\n",
    "    device=device,\n",
    "    n_trials=5    # Optional parameter: number of hyperparameter tuning trials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-inference",
   "metadata": {},
   "source": [
    "<a id='model-inference'></a>\n",
    "#### **4.1.3 Model Inference**\n",
    "\n",
    "Perform prediction and rejection based on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-inference-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict phenotype-associated spots and perform rejection (uncertainty estimation)\n",
    "Predict(\n",
    "    savePath=savePath,\n",
    "    mode=mode,\n",
    "    do_reject=True,        # Optional: whether to perform rejection\n",
    "    tolerance=0.05,        # Optional: tolerance level for rejection\n",
    "    reject_mode=\"GMM\"      # Optional: rejection mode (e.g., \"GMM\" for Gaussian Mixture Model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identify-hubs-and-significant-clusters",
   "metadata": {},
   "source": [
    "<a id='identify-hubs-and-significant-clusters'></a>\n",
    "#### **4.1.4 Identify Hubs and Significant Clusters**\n",
    "\n",
    "Identify hub spots and perform permutation tests to determine significant clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identify-hubs-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify hub spots based on categorical columns\n",
    "IdenHub(\n",
    "    savePath=savePath,\n",
    "    cateCol1=\"patho_class\",        # First categorical column (e.g., pathological class)\n",
    "    cateCol2=\"leiden_clusters\",    # Second categorical column (e.g., clustering result)\n",
    "    min_spots=10                   # Optional: minimum number of spots to consider a hub\n",
    ")\n",
    "\n",
    "# Perform permutation tests to identify significant clusters\n",
    "Pcluster(savePath=savePath, clusterColName=\"patho_class\", perm_n=1001)\n",
    "Pcluster(savePath=savePath, clusterColName=\"leiden_clusters\", perm_n=1001)\n",
    "Pcluster(savePath=savePath, clusterColName=\"combine_cluster\", perm_n=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "<a id='visualization'></a>\n",
    "#### **4.1.5 Visualization**\n",
    "\n",
    "Visualize the results using various plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prediction scores\n",
    "plot_score_distribution(savePath)  # Displays the probability score distribution\n",
    "\n",
    "# Plot UMAP embedding colored by prediction scores\n",
    "plot_score_umap(savePath, infer_mode)\n",
    "\n",
    "# Plot the distribution of labels among different conditions\n",
    "plot_label_distribution_among_conditions(savePath, group=\"patho_class\")\n",
    "plot_label_distribution_among_conditions(savePath, group=\"leiden_clusters\")\n",
    "plot_label_distribution_among_conditions(savePath, group=\"combine_cluster\")\n",
    "\n",
    "# Plot spatial maps of the spots with cluster labels\n",
    "plot_STmap(savePath=savePath, group=\"combine_cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-expression-and-pathway-enrichment-analysis",
   "metadata": {},
   "source": [
    "<a id='differential-expression-and-pathway-enrichment-analysis'></a>\n",
    "### **4.2 Differential Expression and Pathway Enrichment Analysis**\n",
    "\n",
    "Perform differential expression analysis and pathway enrichment to understand the biological processes involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-expression-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds for differential expression analysis\n",
    "fc_threshold = 2          # Optional: fold-change threshold\n",
    "Pvalue_threshold = 0.05   # Optional: p-value threshold\n",
    "do_p_adjust = True        # Optional: whether to adjust p-values for multiple testing\n",
    "\n",
    "# Perform differential expression analysis\n",
    "DEG_analysis(\n",
    "    savePath=savePath,\n",
    "    fc_threshold=fc_threshold,\n",
    "    Pvalue_threshold=Pvalue_threshold,\n",
    "    do_p_adjust=do_p_adjust\n",
    ")\n",
    "\n",
    "# Plot volcano plots for differential expression results\n",
    "DEG_volcano(\n",
    "    savePath=savePath,\n",
    "    fc_threshold=fc_threshold,\n",
    "    Pvalue_threshold=Pvalue_threshold,\n",
    "    do_p_adjust=do_p_adjust\n",
    ")\n",
    "\n",
    "# Perform pathway enrichment analysis using specified databases\n",
    "# Available databases can be found at: https://maayanlab.cloud/Enrichr/#libraries\n",
    "Pathway_Enrichment(\n",
    "    savePath=savePath,\n",
    "    database=[\"GO_Biological_Process_2023\"]  # Optional: replace with desired databases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-remarks",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Final Remarks:**\n",
    "\n",
    "- Ensure that all required data files are available at the specified paths.\n",
    "- Adjust optional parameters such as thresholds, number of clusters, and batch sizes based on your dataset and computational resources.\n",
    "- The `pretrain_path` should point to the pre-trained model file included in your package.\n",
    "- Consistency of variables like `mode` and `infer_mode` is crucial throughout the script.\n",
    "- Visualization functions help in interpreting the results and understanding the spatial distribution of clusters.\n",
    "- If you encounter any issues or need further clarification on any part of the script, refer to the TiRank documentation or reach out for support.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** To run this notebook interactively:\n",
    "\n",
    "1. Copy and paste the content into a new Jupyter Notebook.\n",
    "2. Ensure that the `TiRank` library and all dependencies are properly installed.\n",
    "3. Update the paths to data files and models according to your local setup.\n",
    "4. Execute the cells sequentially.\n",
    "\n",
    "---\n",
    "\n",
    "# **References**\n",
    "\n",
    "- **TiRank Documentation:** *[Add link to TiRank documentation]*\n",
    "- **Enrichr Libraries:** [https://maayanlab.cloud/Enrichr/#libraries](https://maayanlab.cloud/Enrichr/#libraries)\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to modify the notebook according to your specific needs. If you have any questions or need further assistance, don't hesitate to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
