

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>tirank.Model &mdash; TiRank 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            TiRank
              <img src="../../_static/TiRank_white.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_input.html">Model Input</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CLI Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_st_survival.html">Tutorial 1: Spatial Transcriptomics (ST) + Cox Survival Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_sc_classification.html">Tutorial 2: scRNA-seq + Classification Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GUI Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_web.html">TiRank Web App Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Features Document</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../result_interpretation.html">Result Interpretation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hyperparameters.html">Hyperparameters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TiRank</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">tirank.Model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for tirank.Model</h1><div class="highlight"><pre>
<span></span><span class="c1"># model</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.Loss</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Initial</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">PyTorch model definitions for the TiRank framework.</span>

<span class="sd">This module defines the core neural network architectures, including the</span>
<span class="sd">various encoders (Transformer, MLP, DenseNet), the prediction heads for</span>
<span class="sd">different modes (Cox, Classification, Regression), and the main `TiRankModel`</span>
<span class="sd">that combines them into a multi-task learning framework.</span>
<span class="sd">&quot;&quot;&quot;</span>


<div class="viewcode-block" id="setup_seed">
<a class="viewcode-back" href="../../generated/tirank.Model.setup_seed.html#tirank.Model.setup_seed">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets the random seed for reproducibility across all relevant libraries.</span>

<span class="sd">    Args:</span>
<span class="sd">        seed (int): The random seed to use.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="initial_model_para">
<a class="viewcode-back" href="../../generated/tirank.Model.initial_model_para.html#tirank.Model.initial_model_para">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">initial_model_para</span><span class="p">(</span>
        <span class="n">savePath</span><span class="p">,</span>
        <span class="n">nhead</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">nhid1</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> 
        <span class="n">nhid2</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
        <span class="n">n_output</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">n_pred</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;Cox&quot;</span><span class="p">,</span>
        <span class="n">infer_mode</span><span class="o">=</span><span class="s2">&quot;SC&quot;</span><span class="p">,</span>
        <span class="n">encoder_type</span> <span class="o">=</span> <span class="s2">&quot;MLP&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes and saves the model hyperparameter configuration.</span>

<span class="sd">    This function reads the input data dimensions (e.g., number of gene pairs)</span>
<span class="sd">    and spatial cluster dimensions, combines them with the user-defined</span>
<span class="sd">    hyperparameters, and saves the complete configuration as &#39;model_para.pkl&#39;.</span>

<span class="sd">    Args:</span>
<span class="sd">        savePath (str): The main project directory path.</span>
<span class="sd">        nhead (int, optional): Number of heads for Transformer encoder. Defaults to 2.</span>
<span class="sd">        nhid1 (int, optional): Hidden dimension for the encoder. Defaults to 96.</span>
<span class="sd">        nhid2 (int, optional): Hidden dimension for the predictor heads. Defaults to 8.</span>
<span class="sd">        n_output (int, optional): Output dimension of the encoder (embedding size).</span>
<span class="sd">            Defaults to 32.</span>
<span class="sd">        nlayers (int, optional): Number of layers in the encoder. Defaults to 3.</span>
<span class="sd">        n_pred (int, optional): Output dimension of the predictor (e.g., 1 for Cox/Regression,</span>
<span class="sd">            2 for binary Classification). Defaults to 1.</span>
<span class="sd">        dropout (float, optional): Dropout rate. Defaults to 0.5.</span>
<span class="sd">        mode (str, optional): Analysis mode (&#39;Cox&#39;, &#39;Classification&#39;, &#39;Regression&#39;).</span>
<span class="sd">            Defaults to &quot;Cox&quot;.</span>
<span class="sd">        infer_mode (str, optional): Inference data type (&#39;SC&#39; or &#39;ST&#39;). Defaults to &quot;SC&quot;.</span>
<span class="sd">        encoder_type (str, optional): Type of encoder to use (&#39;MLP&#39;, &#39;Transformer&#39;, &#39;DenseNet&#39;).</span>
<span class="sd">            Defaults to &quot;MLP&quot;.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">savePath_2</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath</span><span class="p">,</span><span class="s2">&quot;2_preprocessing&quot;</span><span class="p">)</span>
    <span class="n">savePath_3</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath</span><span class="p">,</span><span class="s2">&quot;3_Analysis&quot;</span><span class="p">)</span>
    <span class="n">savePath_data2train</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath_3</span><span class="p">,</span><span class="s2">&quot;data2train&quot;</span><span class="p">)</span>

    <span class="c1">## Load train bulk gene pair matrix </span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath_2</span><span class="p">,</span> <span class="s1">&#39;train_bulk_gene_pairs_mat.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">train_bulk_gene_pairs_mat</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1">## Load patholabels</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath_data2train</span><span class="p">,</span> <span class="s1">&#39;patholabels.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">patholabels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">n_patho_cluster</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">patholabels</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="c1"># Pack all the parameters into a dictionary</span>
    <span class="n">model_para</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;n_features&#39;</span><span class="p">:</span> <span class="n">train_bulk_gene_pairs_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;nhead&#39;</span><span class="p">:</span> <span class="n">nhead</span><span class="p">,</span>
        <span class="s1">&#39;nhid1&#39;</span><span class="p">:</span> <span class="n">nhid1</span><span class="p">,</span>
        <span class="s1">&#39;nhid2&#39;</span><span class="p">:</span> <span class="n">nhid2</span><span class="p">,</span>
        <span class="s1">&#39;n_output&#39;</span><span class="p">:</span> <span class="n">n_output</span><span class="p">,</span>
        <span class="s1">&#39;nlayers&#39;</span><span class="p">:</span> <span class="n">nlayers</span><span class="p">,</span>
        <span class="s1">&#39;n_pred&#39;</span><span class="p">:</span> <span class="n">n_pred</span><span class="p">,</span>
        <span class="s2">&quot;n_patho&quot;</span> <span class="p">:</span> <span class="n">n_patho_cluster</span><span class="p">,</span>
        <span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="n">dropout</span><span class="p">,</span>
        <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="n">mode</span><span class="p">,</span>
        <span class="s1">&#39;infer_mode&#39;</span><span class="p">:</span> <span class="n">infer_mode</span><span class="p">,</span>
        <span class="s1">&#39;encoder_type&#39;</span><span class="p">:</span> <span class="n">encoder_type</span><span class="p">,</span>
        <span class="s1">&#39;model_save_path&#39;</span> <span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath_3</span><span class="p">,</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">savePath_3</span><span class="p">,</span> <span class="s1">&#39;model_para.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The parameters setting of model is:&quot;</span><span class="p">,</span> <span class="n">model_para</span><span class="p">)</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_para</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="c1">## bet parameters set</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="kc">None</span></div>



<span class="c1"># Encoder</span>


<div class="viewcode-block" id="TransformerEncoderModel">
<a class="viewcode-back" href="../../generated/tirank.Model.TransformerEncoderModel.html#tirank.Model.TransformerEncoderModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TransformerEncoderModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transformer-based encoder network.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input feature size (number of gene pairs).</span>
<span class="sd">        nhead (int): Number of heads in the multi-head attention models.</span>
<span class="sd">        nhid (int): Dimension of the feedforward network model.</span>
<span class="sd">        nlayers (int): Number of sub-encoder-layers in the encoder.</span>
<span class="sd">        n_output (int): Output embedding dimension.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoderModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;Transformer&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_in</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">)</span>  <span class="c1"># Added line</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="n">encoder_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">encoder_layers</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">n_output</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes weights for the linear layers.&quot;&quot;&quot;</span>
        <span class="n">initrange</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_in</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>  <span class="c1"># Added line</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_in</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>  <span class="c1"># Added line</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the Transformer encoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input feature tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output embedding tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_in</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Added line</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add sequence length dimension</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Remove sequence length dimension for the FC layer</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_out</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embedding</span></div>



<div class="viewcode-block" id="PositionalEncoding">
<a class="viewcode-back" href="../../generated/tirank.Model.PositionalEncoding.html#tirank.Model.PositionalEncoding">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    PositionalEncoding module for Transformer.</span>
<span class="sd">    </span>
<span class="sd">    Injects sinusoidal positional encodings to the input embeddings.</span>

<span class="sd">    Args:</span>
<span class="sd">        d_model (int): The embedding dimension.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.1.</span>
<span class="sd">        max_len (int, optional): The maximum length of the input sequences.</span>
<span class="sd">            Defaults to 5000.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;pe&#39;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for PositionalEncoding.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output tensor with added positional encoding.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>

        

<div class="viewcode-block" id="DenseNetEncoderModel">
<a class="viewcode-back" href="../../generated/tirank.Model.DenseNetEncoderModel.html#tirank.Model.DenseNetEncoderModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DenseNetEncoderModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    DenseNet-style encoder network.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input feature size (number of gene pairs).</span>
<span class="sd">        nlayers (int): Number of dense layers.</span>
<span class="sd">        n_output (int): Output embedding dimension.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">        growth_rate (float, optional): Growth rate for the dense layers.</span>
<span class="sd">            Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">growth_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DenseNetEncoderModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;DenseNet&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">growth_rate</span> <span class="o">=</span> <span class="n">growth_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nlayers</span> <span class="o">=</span> <span class="n">nlayers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_output</span> <span class="o">=</span> <span class="n">n_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="c1"># Calculate the number of output features for each dense layer based on growth rate</span>
        <span class="n">dense_layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_features</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="n">growth_rate</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">)]</span>

        <span class="c1"># Create dense layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dense_layer_sizes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">layer_size</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dense_layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_size</span><span class="p">))</span>
        
        <span class="c1"># Final layer that takes the last dense layer size into account</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dense_layer_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_output</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the DenseNet encoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input feature tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output embedding tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># Compute the current layer&#39;s output</span>
            <span class="n">layer_output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="c1"># Apply activation and dropout to the current layer&#39;s output</span>
            <span class="n">layer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">layer_output</span><span class="p">))</span>
            <span class="c1"># Use the current layer&#39;s output as input for the next layer</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">layer_output</span>

        <span class="c1"># Compute the final embedding without activation or dropout</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embedding</span></div>



<div class="viewcode-block" id="MLPEncoderModel">
<a class="viewcode-back" href="../../generated/tirank.Model.MLPEncoderModel.html#tirank.Model.MLPEncoderModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MLPEncoderModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    MLP-based (Multi-Layer Perceptron) encoder network.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input feature size (number of gene pairs).</span>
<span class="sd">        nhid (int): Dimension of the hidden layers.</span>
<span class="sd">        nlayers (int): Total number of layers (input, hidden, output).</span>
<span class="sd">        n_output (int): Output embedding dimension.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MLPEncoderModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;MLP&#39;</span>

        <span class="c1"># Define hidden layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">nhid</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>

        <span class="c1"># Define model layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">n_output</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the MLP encoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input feature tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output embedding tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embedding</span></div>


<span class="c1"># Risk score Predictor</span>


<div class="viewcode-block" id="RiskscorePredictor">
<a class="viewcode-back" href="../../generated/tirank.Model.RiskscorePredictor.html#tirank.Model.RiskscorePredictor">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RiskscorePredictor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prediction head for &#39;Cox&#39; survival analysis.</span>

<span class="sd">    Predicts a single risk score, applying a sigmoid activation to</span>
<span class="sd">    constrain the output between 0 and 1.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input embedding dimension (from encoder).</span>
<span class="sd">        nhid (int): Hidden dimension of the predictor MLP.</span>
<span class="sd">        nhout (int, optional): Output dimension. Defaults to 1.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nhout</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RiskscorePredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">RiskscoreMLP</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="c1"># nn.Linear(nhid, nhid),</span>
            <span class="c1"># nn.LeakyReLU(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">nhout</span><span class="p">),</span>
            <span class="c1"># nn.Linear(n_features, nhout),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the risk score predictor.</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding (torch.Tensor): Input embedding tensor from the encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Predicted risk score (scalar tensor).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">risk_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">RiskscoreMLP</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">risk_score</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


<span class="c1"># Regression score Predictor</span>


<div class="viewcode-block" id="RegscorePredictor">
<a class="viewcode-back" href="../../generated/tirank.Model.RegscorePredictor.html#tirank.Model.RegscorePredictor">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RegscorePredictor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prediction head for &#39;Regression&#39; analysis.</span>

<span class="sd">    Predicts a single continuous value. No output activation is applied.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input embedding dimension (from encoder).</span>
<span class="sd">        nhid (int): Hidden dimension of the predictor MLP.</span>
<span class="sd">        nhout (int, optional): Output dimension. Defaults to 1.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nhout</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RegscorePredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">RegscoreMLP</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="c1"># nn.Linear(nhid, nhid),</span>
            <span class="c1"># nn.LeakyReLU(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">nhout</span><span class="p">),</span>
            <span class="c1"># nn.Linear(n_features, nhout),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the regression score predictor.</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding (torch.Tensor): Input embedding tensor from the encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Predicted continuous value (scalar tensor).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">risk_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">RegscoreMLP</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">risk_score</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>


<span class="c1"># Bionomial Predictor</span>


<div class="viewcode-block" id="ClassscorePredictor">
<a class="viewcode-back" href="../../generated/tirank.Model.ClassscorePredictor.html#tirank.Model.ClassscorePredictor">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ClassscorePredictor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prediction head for &#39;Classification&#39; analysis.</span>

<span class="sd">    Predicts class probabilities using a Softmax activation.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input embedding dimension (from encoder).</span>
<span class="sd">        nhid (int): Hidden dimension of the predictor MLP.</span>
<span class="sd">        nhout (int, optional): Output dimension (number of classes). Defaults to 2.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nhout</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassscorePredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ClassscoreMLP</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="c1"># nn.Linear(nhid, nhid),</span>
            <span class="c1"># nn.LeakyReLU(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">nhout</span><span class="p">),</span>
            <span class="c1"># nn.Linear(n_features, nhout),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the classification score predictor.</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding (torch.Tensor): Input embedding tensor from the encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Predicted class probabilities.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">proba_score</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ClassscoreMLP</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">proba_score</span></div>



<span class="c1"># Pathology Predictor</span>


<div class="viewcode-block" id="PathologyPredictor">
<a class="viewcode-back" href="../../generated/tirank.Model.PathologyPredictor.html#tirank.Model.PathologyPredictor">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PathologyPredictor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Auxiliary prediction head for spatial pathology class.</span>

<span class="sd">    Used for the WSI-guided spatial location-aware module in ST mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input embedding dimension (from encoder).</span>
<span class="sd">        nhid (int): Hidden dimension of the predictor MLP.</span>
<span class="sd">        nclass (int): Number of pathology classes to predict.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nclass</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PathologyPredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PathologyMLP</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">nhid</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="c1"># nn.Linear(nhid, nhid),</span>
            <span class="c1"># nn.LeakyReLU(),</span>
            <span class="c1"># nn.Dropout(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nhid</span><span class="p">,</span> <span class="n">nclass</span><span class="p">),</span>
            <span class="c1"># nn.Linear(n_features, nclass),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass for the pathology predictor.</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding (torch.Tensor): Input embedding tensor from the encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Predicted pathology class probabilities.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pathology_score</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PathologyMLP</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">pathology_score</span></div>


<span class="c1"># Main network</span>


<div class="viewcode-block" id="TiRankModel">
<a class="viewcode-back" href="../../generated/tirank.Model.TiRankModel.html#tirank.Model.TiRankModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TiRankModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The main TiRank multi-task learning model.</span>

<span class="sd">    This model combines one of the available encoders (MLP, Transformer,</span>
<span class="sd">    DenseNet) with a primary prediction head (for Cox, Classification, or</span>
<span class="sd">    Regression) and an optional auxiliary head for pathology prediction</span>
<span class="sd">    (used in ST mode). It also includes a learnable feature weight layer</span>
<span class="sd">    for L1 regularization.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_features (int): Input feature size (number of gene pairs).</span>
<span class="sd">        nhead (int): Number of heads for Transformer.</span>
<span class="sd">        nhid1 (int): Hidden dimension for the encoder.</span>
<span class="sd">        nhid2 (int): Hidden dimension for the predictor heads.</span>
<span class="sd">        nlayers (int): Number of layers in the encoder.</span>
<span class="sd">        n_output (int): Output dimension of the encoder (embedding size).</span>
<span class="sd">        n_pred (int, optional): Output dimension of the primary predictor.</span>
<span class="sd">            Defaults to 1.</span>
<span class="sd">        n_patho (int, optional): Output dimension of the pathology predictor</span>
<span class="sd">            (number of classes). Defaults to 0.</span>
<span class="sd">        dropout (float, optional): Dropout value. Defaults to 0.5.</span>
<span class="sd">        mode (str, optional): Analysis mode (&#39;Cox&#39;, &#39;Classification&#39;, &#39;Regression&#39;).</span>
<span class="sd">            Defaults to &quot;Cox&quot;.</span>
<span class="sd">        encoder_type (str, optional): Type of encoder to use. Defaults to &quot;MLP&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">nhid1</span><span class="p">,</span> <span class="n">nhid2</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">n_pred</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_patho</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Cox&quot;</span><span class="p">,</span> <span class="n">encoder_type</span><span class="o">=</span><span class="s2">&quot;MLP&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TiRankModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Initialize the learnable weight matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">)</span>

        <span class="c1">## Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_type</span> <span class="o">=</span> <span class="n">encoder_type</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_type</span> <span class="o">==</span> <span class="s2">&quot;Transformer&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoderModel</span><span class="p">(</span>
                <span class="n">n_features</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">nhid1</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_type</span> <span class="o">==</span> <span class="s2">&quot;MLP&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">MLPEncoderModel</span><span class="p">(</span>
                <span class="n">n_features</span><span class="p">,</span> <span class="n">nhid1</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_type</span> <span class="o">==</span> <span class="s2">&quot;DenseNet&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">DenseNetEncoderModel</span><span class="p">(</span>
                <span class="n">n_features</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported Encoder Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1">## Mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;Cox&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">RiskscorePredictor</span><span class="p">(</span>
                <span class="n">n_output</span><span class="p">,</span> <span class="n">nhid2</span><span class="p">,</span> <span class="n">n_pred</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;Regression&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">RegscorePredictor</span><span class="p">(</span>
                <span class="n">n_output</span><span class="p">,</span> <span class="n">nhid2</span><span class="p">,</span> <span class="n">n_pred</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;Classification&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">ClassscorePredictor</span><span class="p">(</span>
                <span class="n">n_output</span><span class="p">,</span> <span class="n">nhid2</span><span class="p">,</span> <span class="n">n_pred</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
                
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported Mode: </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pathologpredictor</span> <span class="o">=</span> <span class="n">PathologyPredictor</span><span class="p">(</span>
            <span class="n">n_output</span><span class="p">,</span> <span class="n">nhid2</span><span class="p">,</span> <span class="n">n_patho</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The main forward pass for the TiRank model.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input gene pair feature tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - torch.Tensor: The learned embedding.</span>
<span class="sd">                - torch.Tensor: The primary prediction (risk score, class, etc.).</span>
<span class="sd">                - torch.Tensor: The auxiliary pathology prediction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scaled_x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="o">.</span><span class="n">T</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">scaled_x</span><span class="p">)</span>
        <span class="n">risk_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
        <span class="n">patho_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pathologpredictor</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">risk_score</span><span class="p">,</span> <span class="n">patho_pred</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies Xavier uniform initialization to linear layers.</span>

<span class="sd">        Args:</span>
<span class="sd">            m (nn.Module): A module (or layer) from the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="c1"># print(&quot;Perfoem xavier_uniform initiate&quot;)</span>
            <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, LenisLin.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>